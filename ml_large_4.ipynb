{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vGOu4cYtMXbT",
        "fr7r2eLR7McR",
        "OpOiytMlcj1g"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoIdkT41c+JJQitX4ffPjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rodisolomon/Rodisolomon/blob/main/ml_large_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocess"
      ],
      "metadata": {
        "id": "vGOu4cYtMXbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V--Qsnq92Sbz",
        "outputId": "b83d6b14-0a93-487a-9654-f009b762f432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "from pprint import pprint\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.linalg import eig\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from keras.datasets import mnist\n",
        "from scipy.special import softmax\n",
        "from scipy.special import logsumexp\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "data = np.load(\"/content/drive/MyDrive/ml_large/MNIST_data.npy\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nrows = 4\n",
        "ncols = 5\n",
        "plt.figure(figsize=(ncols*2, nrows*2))\n",
        "for i in range(nrows*ncols):\n",
        "    plt.subplot(nrows, ncols, i+1)\n",
        "    plt.imshow(data[60000+i].reshape((28,28)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hzMt3QNX5kd4",
        "outputId": "97455564-4206-40ac-9c79-34587865ffa5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y), (X2, y2)  = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLXgrO9EV6UH",
        "outputId": "1f459a2d-63e8-4741-f6fb-c082ddf2634b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.vstack((X, X2))\n",
        "y = np.append(y, y2)\n",
        "n1 = int(0.2 * X.shape[0]) #validation\n",
        "n2 = int(0.8 * X.shape[0]) #train+test\n",
        "print(X.shape, y.shape)\n",
        "idx_1 = np.random.choice(X.shape[0], n1, replace=False)\n",
        "idx_2 = np.setdiff1d(np.arange(X.shape[0]), idx_1)\n",
        "\n",
        "X_tot, y_tot, vali_X, vali_y = X[idx_2], y[idx_2], X[idx_1], y[idx_1]\n",
        "\n",
        "idx_3 = np.random.choice(X_tot.shape[0], n1, replace=False)\n",
        "idx_4 = np.setdiff1d(np.arange(X_tot.shape[0]), idx_3)\n",
        "tr_X, tr_y, t_X, t_y = X[idx_4], y[idx_4], X[idx_3], y[idx_3]\n",
        "\n",
        "combo_X, combo_y = np.vstack((tr_X, vali_X)), np.append(tr_y, vali_y)\n",
        "print(tr_X.shape, vali_X.shape, t_X.shape, combo_X.shape)\n",
        "print(tr_y.shape, vali_y.shape, t_y.shape, combo_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-nwgpHvaVYm",
        "outputId": "f85f1bc4-cc14-4300-e5e4-c098d329a747"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 28, 28) (70000,)\n",
            "(42000, 28, 28) (14000, 28, 28) (14000, 28, 28) (56000, 28, 28)\n",
            "(42000,) (14000,) (14000,) (56000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#binarize\n",
        "def binarize(data):\n",
        "  b_data = np.where(data >= 0.5, 1, 0)\n",
        "  return b_data\n",
        "b_tx = binarize(tr_X)\n",
        "#print(b_data[0], b_data.shape)\n",
        "plt.imshow(b_tx[0], cmap=\"gray\")\n",
        "print(b_tx.shape)"
      ],
      "metadata": {
        "id": "DDuKiNsXrMUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e3f85256-c46c-4da3-cd62-7431fa8a4245"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.ma.core import divide\n",
        "#classify into dictionary based on y (label)\n",
        "def classify(x, y):\n",
        "  dic = {}\n",
        "  for i in range(10):\n",
        "    x = binarize(x.reshape(x.shape[0], 784))\n",
        "    dic[i] = x[y == i]\n",
        "    #print(dic[i].shape)\n",
        "  return dic\n",
        "\n",
        "tr_dic, vali_dic, t_dic, combo_dic = classify(tr_X, tr_y), classify(vali_X, vali_y), classify(t_X, t_y), classify(combo_X, combo_y)"
      ],
      "metadata": {
        "id": "Iybn7tCoWoY5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape(x):\n",
        "  return x.reshape(x.shape[0], 784)"
      ],
      "metadata": {
        "id": "e6yh2_B1VOyq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayes rule with Bernoulli mixtures"
      ],
      "metadata": {
        "id": "fr7r2eLR7McR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EM_algo(data, M): \n",
        "  #initiate, input must be binary\n",
        "  data = binarize(data)\n",
        "  n_mean = np.mean(data, axis=0)\n",
        "  d, N = data[0].size, data[:, 0].size\n",
        "\n",
        "  arr = np.random.rand(N, M)\n",
        "  row_sums = arr.sum(axis=1)\n",
        "  W = arr*(10**2) / row_sums.reshape((-1, 1))\n",
        "  lik = 0\n",
        "  #iteration\n",
        "  for i in range(1000):\n",
        "    pi, P = W.mean(axis=0), (data.T @ W + 1) / (W.sum(axis=0) + 2) \n",
        "    f = np.dot(data, np.log(P)) + np.dot(1 - data, np.log(1 - P)) + np.log(pi)\n",
        "    W = np.exp(f - np.max(f, axis=1, keepdims=True))\n",
        "    W = (W+0.0001) / (W.sum(axis=1,keepdims=True) + 0.0001) #prevent from dividing by 0\n",
        "\n",
        "    new_lik = np.sum(np.log(W @ pi + 0.0001))\n",
        "    #print(f\"epoch {i}, newlikelihood = {new_lik}\")\n",
        "    if abs(lik - new_lik) < 0.001: #break/convergenc condition\n",
        "      break #converge\n",
        "    lik = new_lik\n",
        "  return P, pi"
      ],
      "metadata": {
        "id": "1MyIBxWxBmCC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# p, pi = EM_algo(b_tx, 10)\n",
        "# fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(15, 5))\n",
        "# for i in range(10): #when M = 10\n",
        "#   axs[i].imshow(p[:,i].reshape((28, 28)), cmap='gray')\n",
        "\n",
        "\n",
        "# print(p.shape, pi.shape)\n",
        "# tr_dic, vali_dic, t_dic = classify(tr_X), classify(vali_X), classify(t_X)\n",
        "# return -> (784, 10) (10,)\n",
        "\n",
        "# code to test around shape of EM wrapper\n",
        "# product = b_tx @ np.log(p) + (1-b_tx) @ np.log(1-p)\n",
        "# print(b_tx.shape, np.log(p).shape, (b_tx @ np.log(p)).shape, product.shape, pi.shape)\n",
        "# print(product[:1])\n",
        "# f = np.exp(product) @ pi\n",
        "# print(f.shape) "
      ],
      "metadata": {
        "id": "HdKC6__k7gK7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EM_wrapper(tr_dic, vali_X, vali_y): #wrapper fxn\n",
        "  err_rate = []\n",
        "  for M in [1, 5, 10, 20]:\n",
        "    print(f\"========= test mixture model with M = {M} =========\")\n",
        "    f_dic = {}\n",
        "    for y in range(10):\n",
        "      p, pi = EM_algo(tr_dic[y], M)\n",
        "      product = vali_X @ np.log(p) + (1-vali_X) @ np.log(1-p) #ixc + paim, compute maximum of every row\n",
        "      #f2 = np.exp(product*0.001) @ pi #number_of_data:1, choose the biggest one among all y as the right label\n",
        "      f = logsumexp((product*0.001 + np.log(pi)), axis=1)\n",
        "      #print(f[0], f2[0], pi, np.log(pi))\n",
        "      f_dic[y] = f\n",
        "      #print(f)\n",
        "      #print(f\"the first dp with label {y} has result {f[1]}\")\n",
        "    #calculate error rate\n",
        "    predict_label = []\n",
        "    for i in range(vali_y.size):\n",
        "      max_p, max_l = float('-inf'), float('-inf')\n",
        "      for y2 in range(10):\n",
        "        if f_dic[y2][i] > max_p:\n",
        "          max_p, max_l = f_dic[y2][i], y2\n",
        "      predict_label.append(max_l)\n",
        "    err = np.count_nonzero(predict_label != vali_y)\n",
        "    print(f\"error rate for M = {M} is {err/vali_y.size}\")\n",
        "    err_rate.append(err)\n"
      ],
      "metadata": {
        "id": "0jfYt_IUTk-P"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EM_wrapper(tr_dic, vali_X.reshape(vali_X.shape[0], 784), vali_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rByt8MeUE5oM",
        "outputId": "4196e86a-623b-4f06-cfd1-d2a8d167d7fc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= test mixture model with M = 1 =========\n",
            "error rate for M = 1 is 0.27014285714285713\n",
            "========= test mixture model with M = 5 =========\n",
            "error rate for M = 5 is 0.2005\n",
            "========= test mixture model with M = 10 =========\n",
            "error rate for M = 10 is 0.18978571428571428\n",
            "========= test mixture model with M = 20 =========\n",
            "error rate for M = 20 is 0.19235714285714287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the test result above, I decide to choose M = 10 (which gives back the lowest error rate)"
      ],
      "metadata": {
        "id": "fmCryyi1Elv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EM_wrapper_t(tr_dic, vali_X, vali_y, M): #wrapper fxn\n",
        "  print(f\"========= test mixture model with M = {M} =========\")\n",
        "  f_dic = {}\n",
        "  for y in range(10):\n",
        "    p, pi = EM_algo(tr_dic[y], M)\n",
        "    product = vali_X @ np.log(p) + (1-vali_X) @ np.log(1-p) #ixc + paim, compute maximum of every row\n",
        "    #f2 = np.exp(product*0.001) @ pi #number_of_data:1, choose the biggest one among all y as the right label\n",
        "    f = logsumexp((product*0.001 + np.log(pi)), axis=1)\n",
        "    #print(f[0], f2[0], pi, np.log(pi))\n",
        "    f_dic[y] = f\n",
        "    #print(f)\n",
        "    #print(f\"the first dp with label {y} has result {f[1]}\")\n",
        "  #calculate error rate\n",
        "  predict_label = []\n",
        "  for i in range(vali_y.size):\n",
        "    max_p, max_l = float('-inf'), float('-inf')\n",
        "    for y2 in range(10):\n",
        "      if f_dic[y2][i] > max_p:\n",
        "        max_p, max_l = f_dic[y2][i], y2\n",
        "    predict_label.append(max_l)\n",
        "  err = np.count_nonzero(predict_label != vali_y)\n",
        "  print(f\"error rate for M = {M} is {err/vali_y.size}\")\n"
      ],
      "metadata": {
        "id": "zGTMMbwBBsxw"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combo_dic[0].shape, t_X.shape, t_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYLX3vv5UmEc",
        "outputId": "830bb51e-81a0-40bd-9ac9-7faf99f8e0a7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5531, 784) (14000, 28, 28) (14000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EM_wrapper_t(combo_dic, reshape(t_X), t_y, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbLS1iLYTzVN",
        "outputId": "a30e922e-34e8-4c79-8462-8196ce535d37"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= test mixture model with M = 10 =========\n",
            "error rate for M = 10 is 0.20257142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression"
      ],
      "metadata": {
        "id": "ORrQhb-pTaNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### raw data"
      ],
      "metadata": {
        "id": "OpOiytMlcj1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for C in [1e-8, 1e-5, 1e-2, 1, 100, 1e5]:\n",
        "  lr = LogisticRegression(fit_intercept=True, C=C, penalty=\"l2\", multi_class=\"multinomial\", solver=\"lbfgs\")\n",
        "  lr.fit(tr_X.reshape(tr_X.shape[0], 784), tr_y)\n",
        "  lr_r_label = lr.predict(vali_X.reshape(vali_X.shape[0], 784))\n",
        "  lr_r_err = np.count_nonzero(lr_r_label != vali_y)\n",
        "  print(f\"for C = {C}, error rate is {lr_r_err/vali_y.size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SHu_VAxTdMx",
        "outputId": "8b121642-8724-4f97-9237-04a9caf2d68c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for C = 1e-08, error rate is 0.11371428571428571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for C = 1e-05, error rate is 0.07121428571428572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for C = 0.01, error rate is 0.0715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for C = 1, error rate is 0.07107142857142858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for C = 100, error rate is 0.07178571428571429\n",
            "for C = 100000.0, error rate is 0.07185714285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pick C = 100 with error rate of 0.07142857 (all the errors are almost the same)"
      ],
      "metadata": {
        "id": "GF99a1cb-RJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "lr = LogisticRegression(fit_intercept=True, C=100, penalty=\"l2\", multi_class=\"multinomial\", solver=\"lbfgs\")\n",
        "lr.fit(combo_X.reshape(combo_X.shape[0], 784), combo_y)\n",
        "lr_r_label = lr.predict(t_X.reshape(t_y.shape[0], 784))\n",
        "lr_r_err = np.count_nonzero(lr_r_label != t_y)\n",
        "print(f\"for C = {100}, final error rate is {lr_r_err/vali_y.size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvBiblAO-QKy",
        "outputId": "6fcd16a7-9077-4e49-f9b5-bf4d6337016a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for C = 1e-05, final error rate is 0.07942857142857143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA"
      ],
      "metadata": {
        "id": "tT8IsBMwcljt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_PCA(sliced_arr, num):\n",
        "  sliced_arr = sliced_arr.reshape(sliced_arr.shape[0], 784)\n",
        "  features = sliced_arr.T\n",
        "  cov_matrix = np.cov(features)\n",
        "  #cov_matrix[:5]\n",
        "  values, vectors = np.linalg.eig(cov_matrix)\n",
        "  #values[:5]\n",
        "  projected_1 = sliced_arr.dot(vectors.T[0])\n",
        "  projected_2 = sliced_arr.dot(vectors.T[1])\n",
        "\n",
        "  ret = []\n",
        "  for i in range(num):\n",
        "    ret.append(sliced_arr.dot(vectors.T[i]))\n",
        "  ret = np.array(ret)\n",
        "  return np.real(ret.T)"
      ],
      "metadata": {
        "id": "AjpxAOO_cmtA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def PCA_traverse(tr_X, tr_y, vali_X, vali_y): #this is function to find optimal C and PCA\n",
        "  acc = []\n",
        "  tr_X, vali_X = reshape(tr_X), reshape(vali_X)\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "    x_train_tilde = tr_X - tr_X.mean(axis=0)\n",
        "    x_val_tilde = vali_X - vali_X.mean(axis=0)\n",
        "    U, S, Vt = np.linalg.svd(x_train_tilde, full_matrices=False)\n",
        "    for dim in [1, 50, 784]:\n",
        "      Vtm = Vt[:dim]\n",
        "      train_proj = x_train_tilde @ Vtm.T\n",
        "      val_proj = x_val_tilde @ Vtm.T\n",
        "      #PCA_tr_X, PCA_vali_X, = my_PCA(tr_X, dim), my_PCA(vali_X, dim)\n",
        "      for C in [1e-2, 100, 1e5]:\n",
        "        lr = LogisticRegression(fit_intercept=True, C=C, penalty=\"l2\", multi_class=\"multinomial\", solver=\"lbfgs\")\n",
        "        lr.fit(train_proj, tr_y)\n",
        "        lr_r_label = lr.predict(val_proj)\n",
        "        #lr_r_err = np.count_nonzero(lr_r_label != vali_y)\n",
        "        acc.append(accuracy_score(lr_r_label, vali_y))\n",
        "    i = 0\n",
        "    for dim in [1, 50, 784]:\n",
        "      for C in [1e-2, 100, 1e5]:\n",
        "        print(f\"for PCA dim of {dim} and C = {C}, final accuracy rate is {acc[i]}\")\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "5JyYPRZtCiuS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_traverse(tr_X, tr_y, vali_X, vali_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9lFpujzHu-D",
        "outputId": "39bd62c4-a4cb-4af8-a153-6ce0decd2add"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for PCA dim of 1 and C = 0.01, final accuracy rate is 0.30642857142857144\n",
            "for PCA dim of 1 and C = 100, final accuracy rate is 0.3072142857142857\n",
            "for PCA dim of 1 and C = 100000.0, final accuracy rate is 0.3072142857142857\n",
            "for PCA dim of 50 and C = 0.01, final accuracy rate is 0.9055\n",
            "for PCA dim of 50 and C = 100, final accuracy rate is 0.9057142857142857\n",
            "for PCA dim of 50 and C = 100000.0, final accuracy rate is 0.9057142857142857\n",
            "for PCA dim of 784 and C = 0.01, final accuracy rate is 0.9285714285714286\n",
            "for PCA dim of 784 and C = 100, final accuracy rate is 0.9288571428571428\n",
            "for PCA dim of 784 and C = 100000.0, final accuracy rate is 0.9288571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the test, with higher dimension of PCA and C there comes lower error rate, thus I choose PCA dim = 50 (cannot pick 784 cause they'll be the same as raw data) and C = 100 because there's no much difference between c = 1e5 or 100. \n",
        "With higher dimension allowed in PCA, the accuracy also increase, meaning that the feature of data is captured better. when dim = 1, the accuracy is really low, meaning that more feature are required to represent the image"
      ],
      "metadata": {
        "id": "Ac8PwC_yPBIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C, dim = 100, 50\n",
        "combo_X, t_X = reshape(combo_X), reshape(t_X)\n",
        "x_train_tilde = combo_X - combo_X.mean(axis=0)\n",
        "x_val_tilde = t_X - t_X.mean(axis=0)\n",
        "U, S, Vt = np.linalg.svd(x_train_tilde, full_matrices=False)\n",
        "Vtm = Vt[:dim]\n",
        "train_proj = x_train_tilde @ Vtm.T\n",
        "val_proj = x_val_tilde @ Vtm.T\n",
        "\n",
        "#PCA_tr_X, PCA_vali_X, = my_PCA(tr_X, dim), my_PCA(vali_X, dim)\n",
        "lr = LogisticRegression(fit_intercept=True, C=C, penalty=\"l2\", multi_class=\"multinomial\", solver=\"lbfgs\")\n",
        "lr.fit(x_train_tilde, combo_y)\n",
        "lr_r_label = lr.predict(x_val_tilde)\n",
        "print(f\"for PCA dim of {dim} and C = {C}, final accuracy is {accuracy_score(lr_r_label, t_y)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA23WZEsPQLZ",
        "outputId": "e64acef5-67d6-4433-933d-d4b782e46849"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for PCA dim of 50 and C = 100, final accuracy is 0.9132857142857143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both raw data and PCA hav lower error rate than Bayes rule with Bernoulli mixture"
      ],
      "metadata": {
        "id": "XxAIYEYWw0Wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic gradient descent"
      ],
      "metadata": {
        "id": "GNDGHpEGc6dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test with label binarizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "y_oh = LabelBinarizer().fit_transform(tr_y)\n",
        "print(y_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oAhOWX1nmUP",
        "outputId": "694e3116-f679-4a47-b5fc-81db4a439b35"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.special import softmax\n",
        "from scipy.special import logsumexp\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def neg_likelihood(X, y, W):#loss\n",
        "  Z = - X @ W\n",
        "  return (1/X.shape[0]) * (np.trace(X @ W @ y.T) + np.sum(logsumexp(Z, axis=1)))\n",
        "  \n",
        "\n",
        "def gradient(X, y, W, reg):\n",
        "  P = softmax(-X @ W, axis=1) #likelihood\n",
        "  #print(X.T.shape, y.shape, P.shape, W.shape)\n",
        "  N = X.shape[0]\n",
        "  gradient = (1/N)*(X.T @ (y-P)) + 2*reg*W\n",
        "  return gradient\n",
        "\n",
        "def SGD(data, Y, learning_rate, step, reg):\n",
        "  data = data.reshape(data.shape[0], 784)\n",
        "  y = LabelBinarizer().fit_transform(Y)\n",
        "  W = np.zeros((data.shape[1], y.shape[1])) #theta\n",
        "  L = 0\n",
        "  print(\"start training...\")\n",
        "  for i in range(step):\n",
        "    #print(f\"========= Epoch {i} =========\")\n",
        "    batch_idx = np.random.choice(data.shape[0], size=500, replace=False) #I choose batch size = 50\n",
        "    batch_X, batch_y = data[batch_idx], y[batch_idx]\n",
        "    W -= learning_rate*gradient(batch_X, batch_y, W, reg)\n",
        "    new_L = neg_likelihood(batch_X, batch_y, W)\n",
        "    if i%200 == 0:\n",
        "      print(f\"epoch {i}, now loss is {new_L}\")\n",
        "    if abs(L - new_L) < 1e-7:\n",
        "      print(\"converge\")\n",
        "      break #converge\n",
        "    L = new_L \n",
        "  return W\n",
        "\n",
        "def err_rate(W, X, y):\n",
        "  X = X.reshape(X.shape[0], 784)\n",
        "  P = softmax((-X @ W) , axis=1)\n",
        "  rate = np.count_nonzero(np.argmax(P, axis=1) != y)/X.shape[0]\n",
        "  return rate"
      ],
      "metadata": {
        "id": "VZd_4eAVF29Q"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning, step = 0.1, 1000\n",
        "for l in [0, 1e-7, 1e-5, 0.001, 0.1]: #I normalize the data below, so accompanying it with smaller lambda\n",
        "  print(f\"========= C {l} =========\")\n",
        "  W = SGD(tr_X/100, tr_y, learning, step, l)\n",
        "  err = err_rate(W, vali_X/100, vali_y) \n",
        "\n",
        "  print(f\"for C = {l}, error rate is {err}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGcSLMQIe2d8",
        "outputId": "14105f39-8036-4399-e5d5-cbe4f0a71452"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= C 0 =========\n",
            "start training...\n",
            "epoch 0, now loss is 1.720052169473933\n",
            "epoch 200, now loss is 0.35682354087625573\n",
            "epoch 400, now loss is 0.2403704713108855\n",
            "epoch 600, now loss is 0.26368788449566183\n",
            "epoch 800, now loss is 0.22497972505924918\n",
            "for C = 0, error rate is 0.08214285714285714\n",
            "========= C 1e-07 =========\n",
            "start training...\n",
            "epoch 0, now loss is 1.6533538958594163\n",
            "epoch 200, now loss is 0.3784568591899006\n",
            "epoch 400, now loss is 0.2998280121147609\n",
            "epoch 600, now loss is 0.2878431420253073\n",
            "epoch 800, now loss is 0.28107623888353556\n",
            "for C = 1e-07, error rate is 0.08021428571428571\n",
            "========= C 1e-05 =========\n",
            "start training...\n",
            "epoch 0, now loss is 1.6752658059929904\n",
            "epoch 200, now loss is 0.3497755057339655\n",
            "epoch 400, now loss is 0.2860141035436145\n",
            "epoch 600, now loss is 0.3241454667158814\n",
            "epoch 800, now loss is 0.28274412877913074\n",
            "for C = 1e-05, error rate is 0.07978571428571428\n",
            "========= C 0.001 =========\n",
            "start training...\n",
            "epoch 0, now loss is 1.7408909930818348\n",
            "epoch 200, now loss is 0.36329636529761955\n",
            "epoch 400, now loss is 0.26220421999198334\n",
            "epoch 600, now loss is 0.25569817638806674\n",
            "epoch 800, now loss is 0.2896253327352597\n",
            "for C = 0.001, error rate is 0.08021428571428571\n",
            "========= C 0.1 =========\n",
            "start training...\n",
            "epoch 0, now loss is 1.67609209254427\n",
            "epoch 200, now loss is 0.5254835469287354\n",
            "epoch 400, now loss is 0.5346960099644493\n",
            "epoch 600, now loss is 0.5581184536791889\n",
            "epoch 800, now loss is 0.5023398280097177\n",
            "for C = 0.1, error rate is 0.12435714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test with different regularization factor $\\lambda$, I pick C = $1/\\lambda$ = 1e-05 (error rate) (there're no much big diffrernt between different reg factor though)"
      ],
      "metadata": {
        "id": "ds9llKAgfWp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test data\n",
        "W_t = SGD(combo_X/100, combo_y, learning, step, 1e-5)\n",
        "err = err_rate(W, t_X/100, t_y) \n",
        "print(f\"final error rate is {err}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eepaYJq7Bmhn",
        "outputId": "d1acd6e7-987d-4912-8366-90cb953c7a22"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start training...\n",
            "epoch 0, now loss is 1.6844762875393127\n",
            "epoch 200, now loss is 0.346113688361821\n",
            "epoch 400, now loss is 0.30455367835248764\n",
            "epoch 600, now loss is 0.2838441133299548\n",
            "epoch 800, now loss is 0.2286968853359922\n",
            "final error rate is 0.13064285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observation: SGD result has slightly larger error rate than simple logistic regression for both raw data, smaller error rate comparing to PCA projection with low dimension"
      ],
      "metadata": {
        "id": "I0w87bnx250U"
      }
    }
  ]
}